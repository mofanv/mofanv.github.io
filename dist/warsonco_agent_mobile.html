<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
    <title>äº§å“å®¢æœæœºå™¨äºº - ç§»åŠ¨ä¼˜åŒ–ç‰ˆ</title>
    <script src="https://cdn.jsdelivr.net/pyodide/v0.28.2/full/pyodide.js"></script>
    <script src="config.js"></script>
    <style>
        /* Base styles optimized for mobile */
        * {
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            margin: 0;
            padding: 16px;
            background: #f5f5f5;
            color: #333;
            line-height: 1.6;
            touch-action: manipulation;
            -webkit-font-smoothing: antialiased;
        }
        .container {
            max-width: 100%;
            margin: 0 auto;
        }
        h2 {
            text-align: center;
            color: #2c3e50;
            margin-bottom: 20px;
            font-size: 1.5rem;
        }

        /* Input and button styles optimized for touch */
        .input-group {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }
        #inputBox {
            flex: 1;
            padding: 14px 16px;
            font-size: 16px;
            border-radius: 10px;
            border: 1px solid #ddd;
            background: white;
            min-height: 50px;
            -webkit-appearance: none;
        }
        button {
            padding: 14px 20px;
            font-size: 16px;
            border-radius: 10px;
            border: none;
            background: #3498db;
            color: white;
            cursor: pointer;
            min-width: 80px;
            font-weight: 600;
            touch-action: manipulation;
        }
        button:active {
            background: #2980b9;
            transform: scale(0.98);
        }
        button:disabled {
            background: #95a5a6;
            cursor: not-allowed;
        }

        /* Output box */
        #outputBox {
            width: 100%;
            min-height: 200px;
            padding: 16px;
            font-size: 15px;
            border-radius: 10px;
            border: 1px solid #ddd;
            background: #111;
            color: #0f0;
            white-space: pre-wrap;
            overflow: auto;
            -webkit-overflow-scrolling: touch;
            line-height: 1.5;
        }
        
        /* Status indicators */
        .status-indicator {
            color: #FFA500;
            font-style: italic;
            margin: 8px 0;
            font-size: 14px;
        }
        
        /* Loading overlay optimized for mobile */
        #loadingOverlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.85);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000;
            color: white;
            font-size: 1.2rem;
            flex-direction: column;
            padding: 20px;
            text-align: center;
        }
        #loadingMessage {
            margin-top: 20px;
            font-size: 1rem;
        }
        
        /* API Key Form */
        #apiKeyForm {
            display: none;
            margin-top: 20px;
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 10px;
            width: 90%;
            max-width: 500px;
        }
        #apiKeyInput {
            width: 100%;
            padding: 14px;
            margin: 12px 0;
            border-radius: 8px;
            border: 1px solid #ddd;
            font-size: 16px;
            background: white;
            -webkit-appearance: none;
        }
        #submitApiKey {
            padding: 14px 20px;
            background: #27ae60;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
        }
        #submitApiKey:active {
            background: #219653;
        }
        .api-key-label {
            font-size: 16px;
            margin-bottom: 12px;
            display: block;
        }
        
        /* Performance warning */
        .performance-warning {
            background: #f39c12;
            color: white;
            padding: 10px;
            border-radius: 8px;
            margin-bottom: 15px;
            text-align: center;
            font-size: 14px;
            display: none;
        }
        
        /* Transformers.js loading indicator */
        #transformersLoading {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 20px;
            border-radius: 10px;
            z-index: 1001;
            text-align: center;
        }
        #transformersProgress {
            margin-top: 10px;
            font-size: 14px;
        }
        .progress-bar {
            width: 100%;
            height: 6px;
            background: #333;
            border-radius: 3px;
            margin-top: 10px;
            overflow: hidden;
        }
        .progress-fill {
            height: 100%;
            background: #3498db;
            width: 0%;
            transition: width 0.3s ease;
        }
        
        /* Skip button for Transformers.js */
        #skipTransformers {
            margin-top: 15px;
            padding: 8px 16px;
            background: #e74c3c;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
        }
        
        /* Responsive adjustments */
        @media (max-width: 480px) {
            body {
                padding: 12px;
            }
            h2 {
                font-size: 1.3rem;
            }
            #inputBox, button {
                padding: 12px 14px;
            }
        }
        
        /* Animation optimizations */
        .typing-cursor {
            display: inline-block;
            background-color: #0f0;
            width: 6px;
            height: 14px;
            animation: blink 1s infinite;
            margin-left: 2px;
            vertical-align: middle;
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0; }
        }
        
        /* Simplified dot animation for mobile */
        .dot-flashing {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 4px;
            background-color: #FFA500;
            animation: dotFlashing 1s infinite linear alternate;
            margin-left: 4px;
        }
        @keyframes dotFlashing {
            0% { opacity: 1; }
            100% { opacity: 0.3; }
        }
    </style>
</head>
<body>
    <div class="performance-warning" id="perfWarning">
        âš ï¸ ç§»åŠ¨è®¾å¤‡æ€§èƒ½æœ‰é™ï¼ŒåŠ è½½å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
    </div>
    
    <div class="container">
        <h2>äº§å“å®¢æœæœºå™¨äºº 1042</h2>
        
        <div class="input-group">
            <input id="inputBox" type="text" placeholder="è¾“å…¥ä½ çš„é—®é¢˜..." disabled />
            <button onclick="sendToPyodide()" disabled>å‘é€</button>
        </div>

        <div id="outputBox"></div>
    </div>

    <div id="loadingOverlay">
        <div>æ­£åœ¨åŠ è½½AIåŠ©æ‰‹...</div>
        <div id="loadingMessage">ğŸ¤– æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“...</div>
        
        <!-- API Key Input Form -->
        <div id="apiKeyForm">
            <span class="api-key-label">ğŸ”‘ è¯·è¾“å…¥æ‚¨çš„DeepSeek APIå¯†é’¥:</span>
            <input type="password" id="apiKeyInput" placeholder="sk-xxxxxxxxxxxxxxxx" />
            <button id="submitApiKey">æäº¤</button>
        </div>
    </div>

    <!-- Transformers.js loading indicator -->
    <div id="transformersLoading">
        <div>åŠ è½½Transformers.jsæ¨¡å‹...</div>
        <div id="transformersProgress">0%</div>
        <div class="progress-bar">
            <div class="progress-fill" id="progressFill"></div>
        </div>
        <button id="skipTransformers">è·³è¿‡æ¨¡å‹åŠ è½½</button>
    </div>

    <script type="module">
        // Use a lighter model for mobile devices with quantization
        const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        const modelName = 'Xenova/all-MiniLM-L6-v2'; // Lightweight model for mobile
        
        // Show loading indicator for Transformers.js
        document.getElementById('transformersLoading').style.display = 'block';
        
        import { pipeline, env } from 'https://gcore.jsdelivr.net/npm/@xenova/transformers@latest';
        
        // Configure environment for mobile optimization
        env.allowRemoteModels = true;
        env.backends.onnx.wasm.numThreads = isMobile ? 1 : 2; // Reduce threads on mobile
        env.backends.onnx.wasm.proxy = true;
        
        // Update progress indicator
        let lastProgressUpdate = 0;
        const progressCallback = (data) => {
            if (data.status === 'progress') {
                const now = Date.now();
                // Throttle progress updates to avoid UI jank
                if (now - lastProgressUpdate > 200) {
                    const percent = Math.round(data.progress * 100);
                    document.getElementById('transformersProgress').textContent = `${percent}%`;
                    document.getElementById('progressFill').style.width = `${percent}%`;
                    lastProgressUpdate = now;
                }
            }
        };
        
        window.embeddingGenerator = null;
        
        async function initTransformers() {
            try {
                console.log('Loading Transformers.js pipeline with mobile optimization...');
                
                // Use a simpler configuration for mobile with quantization
                const config = {
                    quantized: true, // Use quantized model for mobile
                    progress_callback: progressCallback,
                    device: isMobile ? "wasm" : "webgpu", // Use WASM on mobile for stability
                    dtype: {
                        encoder_model: isMobile ? "q4" : "fp32" // Quantize more on mobile
                    }
                };
                
                window.embeddingGenerator = await pipeline('feature-extraction', modelName, config);
                console.log("Transformers.js pipeline created successfully");
                
                // Hide loading indicator
                document.getElementById('transformersLoading').style.display = 'none';
                
                return true;
            } catch (error) {
                console.error("Failed to initialize Transformers.js:", error);
                // Hide loading indicator even on error
                document.getElementById('transformersLoading').style.display = 'none';
                return false;
            }
        }

        // Add event listener for skip button
        document.getElementById('skipTransformers').addEventListener('click', function() {
            console.log("User skipped Transformers.js loading");
            window.transformersInitialized = false;
            document.getElementById('transformersLoading').style.display = 'none';
            const loadingMessage = document.getElementById('loadingMessage');
            if (loadingMessage) {
                loadingMessage.innerHTML = 'Transformers.jså·²è·³è¿‡ï¼Œä½¿ç”¨å¤‡ç”¨æ¨¡å¼ <span class="dot-flashing"></span>';
            }
        });

        // Initialize Transformers.js with a timeout to prevent hanging 
        const transformersInitPromise = initTransformers();
        
        // Set a timeout to prevent the initialization from hanging indefinitely
        const timeoutPromise = new Promise((resolve) => {
            setTimeout(() => {
                console.warn("Transformers.js initialization taking too long, continuing without it");
                // Show error message but continue
                document.getElementById('transformersLoading').style.display = 'none';
                const loadingMessage = document.getElementById('loadingMessage');
                if (loadingMessage) {
                    loadingMessage.innerHTML = 'Transformers.jsåŠ è½½è¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ¨¡å¼ <span class="dot-flashing"></span>';
                }
                resolve(false);
            }, isMobile ? 120000 : 60000); // Increased timeout: 120 seconds on mobile, 60 on desktop
        });

        // Race between initialization and timeout
        Promise.race([transformersInitPromise, timeoutPromise]).then(success => {
            window.transformersInitialized = success;
            if (success) {
                console.log("Transformers.js initialized successfully");
            } else {
                console.warn("Transformers.js initialization failed or timed out");
                // If Transformers.js fails, we'll handle it in the main initialization
            }
        }).catch(error => {
            console.error("Error in Transformers.js initialization:", error);
            window.transformersInitialized = false;
            document.getElementById('transformersLoading').style.display = 'none';
        });
    </script>

    <script type="text/javascript">
      // Show performance warning on mobile
      if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
        document.getElementById('perfWarning').style.display = 'block';
      }
      
      let pyodide;
      let isStreaming = false;
      let currentStream = null;
      let apiKeyProvided = false;
      let isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      
      // Function to update status from Python
      function updateStatus(message) {
        showStatus(message + " <span class='dot-flashing'></span>");
        
        // Also update the loading message if overlay is still visible
        const loadingMessage = document.getElementById('loadingMessage');
        if (loadingMessage) {
          loadingMessage.textContent = message;
        }
      }

      // Function to check if API key is provided
      function checkApiKey() {
        // Wait for config to load
        if (!window.APP_CONFIG) {
          setTimeout(checkApiKey, 100);
          return;
        }
        
        const JS_DEEPSEEK_API_KEY = window.APP_CONFIG.DEEPSEEK_API_KEY;
        
        // If no API key in config, show the input form
        if (!JS_DEEPSEEK_API_KEY || JS_DEEPSEEK_API_KEY === "your_deepseek_api_key_here") {
          document.getElementById('apiKeyForm').style.display = 'block';
          document.getElementById('loadingMessage').textContent = 'éœ€è¦DeepSeek APIå¯†é’¥æ‰èƒ½ç»§ç»­';
        } else {
          // API key exists in config, proceed with initialization
          apiKeyProvided = true;
          main();
        }
      }

      // Handle API key submission
      document.getElementById('submitApiKey').addEventListener('click', function() {
        const apiKey = document.getElementById('apiKeyInput').value.trim();
        if (apiKey) {
          // Set the API key in the config
          if (!window.APP_CONFIG) window.APP_CONFIG = {};
          window.APP_CONFIG.DEEPSEEK_API_KEY = apiKey;
          apiKeyProvided = true;
          
          // Hide the form and continue initialization
          document.getElementById('apiKeyForm').style.display = 'none';
          document.getElementById('loadingMessage').textContent = 'ğŸ¤– æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“...';
          main();
        } else {
          alert('è¯·è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥');
        }
      });

      // Also allow Enter key to submit
      document.getElementById('apiKeyInput').addEventListener('keypress', function(e) {
        if (e.key === 'Enter') {
          document.getElementById('submitApiKey').click();
        }
      });

      async function main(){
        // Show loading overlay initially
        document.getElementById('loadingOverlay').style.display = 'flex';
        
        // Wait for config and API key
        while (!window.APP_CONFIG || !apiKeyProvided) {
          await new Promise(r => setTimeout(r, 50));
        }
        
        const JS_LLM_MODE = window.APP_CONFIG.LLM_MODE;
        const JS_DEEPSEEK_API_KEY = window.APP_CONFIG.DEEPSEEK_API_KEY;
        const JS_HUGGINGFACEHUB_API_TOKEN = window.APP_CONFIG.HUGGINGFACEHUB_API_TOKEN;
        const JS_TAVILY_API_KEY = window.APP_CONFIG.TAVILY_API_KEY;
        
        // Default to transformersjs for mobile if not specified
        let JS_EMBEDDING_MODE = window.APP_CONFIG.EMBEDDING_MODE || (isMobile ? "transformersjs" : "local");

        // Wait for Transformers.js to initialize if we're using it
        if (JS_EMBEDDING_MODE === "transformersjs") {
          updateStatus("ğŸ”„ æ­£åœ¨åŠ è½½Transformers.jsæ¨¡å‹...");
          
          // Show Transformers.js loading indicator
          document.getElementById('transformersLoading').style.display = 'block';
          
          // Wait for Transformers.js to initialize or timeout
          let waitTime = 0;
          while (window.transformersInitialized === undefined && waitTime < 120000) {
            await new Promise(r => setTimeout(r, 100));
            waitTime += 100;
          }
          
          // Hide Transformers.js loading indicator
          document.getElementById('transformersLoading').style.display = 'none';
          
          if (!window.transformersInitialized) {
            console.warn("Transformers.js failed to initialize, falling back to local API mode");
            JS_EMBEDDING_MODE = "local";
            // Update the config to reflect the change
            window.APP_CONFIG.EMBEDDING_MODE = "local";
          }
        }
        
        // Initialize Pyodide with a progress callback
        updateStatus("ğŸ”„ æ­£åœ¨åŠ è½½Pyodide...");
        pyodide = await loadPyodide({
          // Show loading progress for better UX
          stdout: msg => console.log(msg),
          stderr: msg => console.error(msg)
        });
        
        // Register the updateStatus function in Python's global scope
        pyodide.globals.set("updateStatus", updateStatus);
        // Pass embedding mode to Python
        pyodide.globals.set("JS_EMBEDDING_MODE", JS_EMBEDDING_MODE);

        // Install packages first so we can use NumPy for fallback
        updateStatus("ğŸ“¦ æ­£åœ¨å®‰è£…PythonåŒ…...");
        await pyodide.loadPackage("micropip");
        
        // Install only essential packages for mobile 
        const packagesToInstall = ["requests==2.32.5", "numpy", "langchain", "langchain_deepseek"];
        
        console.log(await pyodide.runPythonAsync(`
            import sys
            sys.version

            import micropip

            await micropip.install(${JSON.stringify(packagesToInstall)}, keep_going=True)
        `));
        
        // --- 1. Fetch embeddings.npy with progress tracking ---
        updateStatus("ğŸ“¥ æ­£åœ¨åŠ è½½åµŒå…¥æ•°æ®...");
        try {
          const npyResp = await fetchWithProgress("https://mofanv.github.io/dist/embeddings.npy", 
            "embeddings.npy", "åµŒå…¥æ•°æ®");
          if (!npyResp.ok) throw new Error("åŠ è½½RAG Embeddingæ•°æ®æ–‡ä»¶å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ˜¯å¦æœ‰è®¿é—®æƒé™ã€‚");
          const npyBuffer = await npyResp.arrayBuffer();
          pyodide.FS.writeFile("/embeddings.npy", new Uint8Array(npyBuffer));
        } catch (error) {
          console.error("Error loading embeddings:", error);
          updateStatus("âŒ åŠ è½½åµŒå…¥æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®");
          // Create a valid fallback .npy file using NumPy
          await pyodide.runPythonAsync(`
            import numpy as np
            fallback_embeddings = np.zeros((1, 384), dtype=np.float32)
            np.save("/embeddings.npy", fallback_embeddings)
          `);
        }

        // --- 2. Fetch embeddings_docs.json with progress tracking ---
        updateStatus("ğŸ“¥ æ­£åœ¨åŠ è½½æ–‡æ¡£æ•°æ®...");
        try {
          const jsonResp = await fetchWithProgress("https://mofanv.github.io/dist/embeddings_docs.json", 
            "embeddings_docs.json", "æ–‡æ¡£æ•°æ®");
          if (!jsonResp.ok) throw new Error("åŠ è½½RAG Docsæ•°æ®æ–‡ä»¶å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ˜¯å¦æœ‰è®¿é—®æƒé™ã€‚");
          const jsonText = await jsonResp.text();
          pyodide.FS.writeFile("/embeddings_docs.json", jsonText);
        } catch (error) {
          console.error("Error loading docs:", error);
          updateStatus("âŒ åŠ è½½æ–‡æ¡£æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®");
          // Continue with a fallback - create empty docs
          const fallbackDocs = JSON.stringify([{text: "No data available", metadata: {url: "N/A"}}]);
          pyodide.FS.writeFile("/embeddings_docs.json", fallbackDocs);
        }
        
        await pyodide.runPythonAsync(`
            import os
            os.environ['DEEPSEEK_API_KEY'] = "${JS_DEEPSEEK_API_KEY}"
            os.environ['HUGGINGFACEHUB_API_TOKEN'] = "${JS_HUGGINGFACEHUB_API_TOKEN}"
            os.environ['LLM_MODE'] = "${JS_LLM_MODE}"
            os.environ['EMBEDDING_MODE'] = "${JS_EMBEDDING_MODE}"
            print("API Key set:", os.environ['DEEPSEEK_API_KEY'][:6] + "...")
            print("LLM Mode:", os.environ['LLM_MODE'])
            print("Embedding Mode:", os.environ['EMBEDDING_MODE'])
        `);
        
        // Now run the main Python code
        updateStatus("ğŸ æ­£åœ¨æ‰§è¡ŒPythonä»£ç ...");
        
        // Use a simplified Python code for mobile to improve performance 
        const pythonCode = getPythonCode(JS_EMBEDDING_MODE);
        
        await pyodide.runPythonAsync(pythonCode);
        
        // Hide the loading overlay and enable input
        document.getElementById('loadingOverlay').style.display = 'none';
        document.getElementById('inputBox').disabled = false;
        document.querySelector('button').disabled = false;
        document.getElementById('inputBox').focus();
        
        // Clear any status messages in the chat output
        hideStatus();
      }
      
      // Function to fetch with progress tracking
      async function fetchWithProgress(url, filename, description) {
        const response = await fetch(url);
        const contentLength = response.headers.get('content-length');
        const total = parseInt(contentLength, 10);
        let loaded = 0;
        
        // Create a reader to track progress
        const reader = response.body.getReader();
        const chunks = [];
        
        while(true) {
          const {done, value} = await reader.read();
          if (done) break;
          
          chunks.push(value);
          loaded += value.length;
          
          // Update progress every 10% or 1MB
          if (total && (loaded / total > 0.1 || loaded % (1024 * 1024) === 0)) {
            const percent = total ? Math.round((loaded / total) * 100) : 0;
            updateStatus(`ğŸ“¥ æ­£åœ¨åŠ è½½${description}... ${percent}%`);
          }
        }
        
        // Combine chunks
        const blob = new Blob(chunks);
        return new Response(blob);
      }
      
      // Get appropriate Python code based on embedding mode
      function getPythonCode(embeddingMode) {
        // Mobile-optimized Python code with better error handling
        return `
import json
import os
import numpy as np
from langchain.schema import Document
from langchain.tools import tool
from langchain.memory import ConversationBufferMemory
from langchain.agents import initialize_agent, AgentType
from langchain_deepseek import ChatDeepSeek

# ===================== LLM SELECTION =====================
LLM_MODE = os.getenv("LLM_MODE", "deepseek")
EMBEDDING_MODE = os.getenv("EMBEDDING_MODE", "local")

if LLM_MODE == "deepseek":
    llm = ChatDeepSeek(model="deepseek-chat", timeout=60)
    print("Using DeepSeek as the Agent LLM...")
else:
    raise ValueError(f"Unsupported LLM_MODE: {LLM_MODE}")

print(f"Using embedding mode: {EMBEDDING_MODE}")

# ===================== KNOWLEDGE BASE =====================
EMBEDDINGS_FILE = "/embeddings.npy"
DOCS_FILE = "/embeddings_docs.json"

# Load precomputed embeddings
try:
    vectors = np.load(EMBEDDINGS_FILE, allow_pickle=True)
    vectors = np.array(vectors, dtype=np.float32)
    # Normalize vectors
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    vectors /= (norms + 1e-10)
except:
    vectors = np.zeros((1, 384), dtype=np.float32)  # Fallback

# Load metadata/docs
try:
    with open(DOCS_FILE, "r", encoding="utf-8") as f:
        docs_store = [Document(page_content=d["text"], metadata=d["metadata"]) for d in json.load(f)]
except:
    docs_store = [Document(page_content="No data available", metadata={})]  # Fallback

def get_embedding(text: str):
    """Get embedding based on mode"""
    updateStatus("ğŸ” æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...")
    try:
        if EMBEDDING_MODE == "transformersjs" and "js_embedding" in globals():
            # Use Transformers.js embedding from JavaScript
            import numpy as np
            emb = np.array(js_embedding, dtype=np.float32)
            # Normalize
            norm = np.linalg.norm(emb)
            if norm > 0:
                emb /= norm
            return emb
        else:
            # Fallback to simple embedding for mobile
            import numpy as np
            # Simple hash-based embedding for mobile fallback
            words = text.lower().split()
            emb = np.zeros(384, dtype=np.float32)
            count = 0
            for word in words:
                if len(word) > 2:  # Skip very short words
                    seed = hash(word) % 1000
                    np.random.seed(seed)
                    emb += np.random.rand(384).astype(np.float32) - 0.5
                    count += 1
            if count > 0:
                emb /= count
                norm = np.linalg.norm(emb)
                if norm > 0:
                    emb /= norm
            return emb
    except Exception as e:
        print(f"[Embedding Error] {e}")
        return np.zeros(vectors.shape[1], dtype=np.float32) if vectors.size > 0 else np.zeros(384, dtype=np.float32)

def query_kb(query: str, k: int = 3):
    """Query the knowledge base"""
    updateStatus("ğŸ“š æ­£åœ¨æœç´¢çŸ¥è¯†åº“...")
    q_vec = get_embedding(query)
    
    # Ensure q_vec is 2D for consistent dot product
    if q_vec.ndim == 1:
        q_vec = q_vec.reshape(1, -1)
    
    # Check if vectors are available
    if vectors.size == 0 or vectors.shape[1] != q_vec.shape[1]:
        updateStatus("âš ï¸ çŸ¥è¯†åº“æœªåŠ è½½ï¼Œä½¿ç”¨é»˜è®¤å›å¤")
        return [Document(page_content="çŸ¥è¯†åº“æš‚ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•", metadata={"url": "N/A"})]
    
    try:
        # Fixed similarity computation - removed erroneous [0]
        sims = np.dot(q_vec, vectors.T)
        
        # Handle both 1D and 2D results
        if sims.ndim > 1:
            sims = sims[0]
            
        top_idx = sims.argsort()[-k:][::-1]
        updateStatus("âœ… å·²æ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
        return [docs_store[i] for i in top_idx]
    except Exception as e:
        print(f"Error in similarity computation: {e}")
        # Return empty results on error
        return []

# ===================== TOOLS =====================
@tool
def search_knowledge(query: str):
    """æ£€ç´¢çŸ¥è¯†åº“ç›¸å…³ä¿¡æ¯"""
    updateStatus("ğŸ” æ­£åœ¨æœç´¢çŸ¥è¯†åº“...")
    docs = query_kb(query, k=3)
    return [f"{d.page_content}\\næ¥æº: {d.metadata.get('url','æœªçŸ¥æ¥æº')}" for d in docs]

@tool
def get_price_info(query: str):
    """æ£€ç´¢ä»·æ ¼ç›¸å…³ä¿¡æ¯"""
    updateStatus("ğŸ’° æ­£åœ¨æœç´¢ä»·æ ¼ä¿¡æ¯...")
    docs = query_kb(query, k=3)
    price_docs = [d for d in docs if "ä»·" in d.page_content or "ï¿¥" in d.page_content]
    return [f"{d.page_content}\\næ¥æº: {d.metadata.get('url','æœªçŸ¥æ¥æº')}" for d in price_docs] if price_docs else "æœªæ‰¾åˆ°ç›¸å…³ä»·æ ¼ä¿¡æ¯"

# ===================== AGENT SETUP =====================
tools = [search_knowledge, get_price_info]

system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹ï¼ŒåŸºäºçŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœé—®é¢˜ä¸æ¸…æ¥šï¼Œè¯·ç¤¼è²Œè¯·æ±‚æ¾„æ¸…ã€‚"

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    system_message=system_prompt
)

updateStatus("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“...")
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=False,  # Reduced verbosity for mobile
    max_iterations=3,  # Limit iterations for mobile
    early_stopping_method="generate"
)

# ===================== AGENT INTERFACE =====================
class ProductAssistantAgent:
    def __init__(self, agent_llm):
        self.agent = agent_llm

    def is_input_relevant(self, user_input: str, threshold=0.2):
        updateStatus("ğŸ” æ­£åœ¨æ£€æŸ¥æŸ¥è¯¢ç›¸å…³æ€§...")
        q_vec = get_embedding(user_input)
        
        # If no vectors available, assume input is relevant
        if vectors.size == 0:
            return True
            
        # Ensure q_vec is 2D for consistent dot product
        if q_vec.ndim == 1:
            q_vec = q_vec.reshape(1, -1)
            
        vecs = vectors.astype(np.float32)  # ensure numeric

        if q_vec.shape[1] != vecs.shape[1]:
            return False

        try:
            updateStatus("ğŸ“Š æ­£åœ¨è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°...")
            # Fixed similarity computation - removed erroneous [0]
            sims = np.dot(q_vec, vecs.T)
            
            # Handle both 1D and 2D results
            if sims.ndim > 1:
                sims = sims[0]
                
            if sims.size == 0:
                return False
            max_sim = float(np.max(sims))
            return max_sim >= float(threshold)
        except (TypeError, ValueError) as e:
            print(f"Error in relevance check: {e}")
            return False

    async def process_message(self, message: str):
        if not self.is_input_relevant(message):
            return "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç†è§£æ‚¨çš„é—®é¢˜ã€‚å¯ä»¥è¯·æ‚¨æè¿°å¾—æ›´æ¸…æ¥šå—ï¼Ÿ"

        # Run agent
        updateStatus("ğŸ§  æ­£åœ¨æ€è€ƒå¦‚ä½•å›ç­”...")
        try:
            ai_raw = self.agent.invoke({"input": message})

            # Only keep the AI response content
            if hasattr(ai_raw, "content"):
                ai_response = ai_raw.content
            elif isinstance(ai_raw, dict) and "output" in ai_raw:
                ai_response = ai_raw["output"]
            else:
                ai_response = str(ai_raw)

            # Handle API errors
            if "invalid response" in ai_response.lower() or "api" in ai_response.lower():
                return "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚"
                
            return ai_response
        except Exception as e:
            error_msg = str(e)
            if "invalid response" in error_msg.lower() or "api" in error_msg.lower():
                return "DeepSeek APIè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥ã€‚"
            return f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {error_msg}"

# ===================== GLOBAL AGENT INSTANCE =====================
agent_instance = ProductAssistantAgent(agent_llm=agent)

# ===================== MAIN FUNCTION =====================
async def main_function(user_input: str) -> str:
    updateStatus("ğŸ¤– æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...")
    try:
        res = await agent_instance.process_message(user_input)
        return res
    except Exception as e:
        error_msg = str(e)
        if "invalid response" in error_msg.lower() or "api" in error_msg.lower():
            return "DeepSeek APIè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥ã€‚"
        return f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {error_msg}"
          `;
      }
      
      // Start checking for API key when page loads
      checkApiKey();

      // === Chat UI functions ===
      async function sendToPyodide() {
        if (isStreaming) {
          // If already streaming, cancel the current stream
          if (currentStream) {
            clearInterval(currentStream);
            currentStream = null;
          }
          // Remove the cursor
          const cursor = document.querySelector('.typing-cursor');
          if (cursor) cursor.remove();
          isStreaming = false;
        }
        
        const userInput = document.getElementById("inputBox").value;
        if (!userInput.trim()) return;
        
        logOutput("ğŸ‘¤ ç”¨æˆ·: " + userInput, "user");

        // Disable input during processing
        document.getElementById("inputBox").value = "";
        document.getElementById("inputBox").disabled = true;
        document.querySelector('button').disabled = true;

        // Show initial status
        showStatus("ğŸ¤– æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ <span class='dot-flashing'></span>");

        try {
          // Check which embedding mode to use
          const embeddingMode = window.APP_CONFIG.EMBEDDING_MODE || "local";
          
          if (embeddingMode === "transformersjs" && window.embeddingGenerator) {
            // Use Transformers.js to generate embeddings
            showStatus("ğŸ§  æ­£åœ¨ä½¿ç”¨ Transformers.js ç”ŸæˆåµŒå…¥ <span class='dot-flashing'></span>");
            
            // Generate embedding vector
            const output = await window.embeddingGenerator(userInput, { pooling: 'mean', normalize: true });
            const embeddingArray = Array.from(output.data);
            
            // Pass embedding vector to Pyodide
            pyodide.globals.set("js_embedding", embeddingArray);
          }
          
          // Process user input
          const result = await pyodide.runPythonAsync(`
              await main_function(${JSON.stringify(userInput)})
          `);
          
          // Clear status
          hideStatus();
          
          // Start streaming the response
          streamOutput("ğŸ¤– åŠ©æ‰‹: " + result, "assistant");
        } catch (err) {
          // Clear status
          hideStatus();
          
          logOutput("âš ï¸ é”™è¯¯: " + err, "error");
          // Re-enable input on error
          document.getElementById("inputBox").disabled = false;
          document.querySelector('button').disabled = false;
        }
      }

      document.getElementById("inputBox").addEventListener("keydown", function(event) {
          if (event.key === 'Enter') {
              event.preventDefault(); // prevent newline in input
              sendToPyodide();
          }
      });

      function logOutput(message, type="assistant") {
          const out = document.getElementById("outputBox");

          // Create a span element for message
          const span = document.createElement("span");
          span.textContent = message;

          if (type === "user") {
              span.style.color = "#1E90FF"; // blue for ç”¨æˆ·
              span.style.fontWeight = "bold";
          } else if (type === "assistant") {
              span.style.color = "#32CD32"; // green for åŠ©æ‰‹
          } else if (type === "error") {
              span.style.color = "#FF4500"; // red for errors
              span.style.fontWeight = "bold";
          }

          out.appendChild(span);
          out.appendChild(document.createElement("br")); // line break
          out.appendChild(document.createElement("br")); // extra spacing

          out.scrollTop = out.scrollHeight; // auto-scroll
      }
      
      function streamOutput(message, type) {
          isStreaming = true;
          const out = document.getElementById("outputBox");
          
          // Create a span for the message
          const span = document.createElement("span");
          if (type === "assistant") {
              span.style.color = "#32CD32"; // green for åŠ©æ‰‹
          }
          
          out.appendChild(span);
          
          // Create a blinking cursor
          const cursor = document.createElement("span");
          cursor.className = "typing-cursor";
          out.appendChild(cursor);
          
          let i = 0;
          currentStream = setInterval(() => {
              if (i < message.length) {
                  span.textContent += message[i];
                  i++;
                  out.scrollTop = out.scrollHeight; // auto-scroll
              } else {
                  // Finished streaming
                  clearInterval(currentStream);
                  currentStream = null;
                  isStreaming = false;
                  
                  // Remove the cursor
                  cursor.remove();
                  
                  // Add line breaks
                  out.appendChild(document.createElement("br"));
                  out.appendChild(document.createElement("br"));
                  
                  // Re-enable input
                  document.getElementById("inputBox").disabled = false;
                  document.querySelector('button').disabled = false;
                  document.getElementById('inputBox').focus();
              }
          }, 30); // Adjust speed as needed (milliseconds per character)
      }
      
      function showStatus(message) {
          // Remove any existing status
          hideStatus();
          
          const out = document.getElementById("outputBox");
          const statusElement = document.createElement("div");
          statusElement.id = "status-indicator";
          statusElement.className = "status-indicator";
          statusElement.innerHTML = message;
          
          out.appendChild(statusElement);
          out.scrollTop = out.scrollHeight;
      }
      
      function hideStatus() {
          const statusElement = document.getElementById("status-indicator");
          if (statusElement) {
              statusElement.remove();
          }
      }

    </script>
</body>
</html>