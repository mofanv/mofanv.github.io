<!doctype html>
<html>
  <head>
      <script src="https://cdn.jsdelivr.net/pyodide/v0.28.2/full/pyodide.js"></script>
      <script src="config.js"></script>
    <meta charset="UTF-8">
  <title>Pyodide Chat</title>
  <style>
    /* ä¿æŒåŸæœ‰çš„æ ·å¼ä¸å˜ */
    body {
      font-family: Arial, sans-serif;
      margin: 30px;
      background: #f5f5f5;
    }
    #inputBox, #outputBox {
      width: 100%;
      padding: 10px;
      font-size: 16px;
      border-radius: 8px;
      border: 1px solid #ccc;
      margin-bottom: 15px;
      box-sizing: border-box;
    }
    #outputBox {
      background: #111;
      color: #0f0;
      min-height: 150px;
      white-space: pre-wrap;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      border-radius: 8px;
      border: none;
      background: #007bff;
      color: #fff;
      cursor: pointer;
    }
    button:hover {
      background: #0056b3;
    }
    .typing-cursor {
      display: inline-block;
      background-color: #0f0;
      width: 8px;
      height: 16px;
      animation: blink 1s infinite;
      margin-left: 2px;
      vertical-align: middle;
    }
    @keyframes blink {
      0%, 100% { opacity: 1; }
      50% { opacity: 0; }
    }
    .status-indicator {
      color: #FFA500; /* Orange color for status messages */
      font-style: italic;
      margin: 5px 0;
    }
    .dot-flashing {
      position: relative;
      display: inline-block;
      width: 10px;
      height: 10px;
      border-radius: 5px;
      background-color: #FFA500;
      color: #FFA500;
      animation: dotFlashing 1s infinite linear alternate;
      animation-delay: 0.5s;
      margin-left: 5px;
    }
    .dot-flashing::before, .dot-flashing::after {
      content: '';
      display: inline-block;
      position: absolute;
      top: 0;
      width: 10px;
      height: 10px;
      border-radius: 5px;
      background-color: #FFA500;
      color: #FFA500;
    }
    .dot-flashing::before {
      left: -15px;
      animation: dotFlashing 1s infinite alternate;
      animation-delay: 0s;
    }
    .dot-flashing::after {
      left: 15px;
      animation: dotFlashing 1s infinite alternate;
      animation-delay: 1s;
    }
    @keyframes dotFlashing {
      0% {
        background-color: #FFA500;
      }
      50%,
      100% {
        background-color: #ebe6ff;
      }
    }
    #loadingOverlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0, 0, 0, 0.7);
      display: flex;
      justify-content: center;
      align-items: center;
      z-index: 1000;
      color: white;
      font-size: 24px;
      flex-direction: column;
    }
    #loadingMessage {
      margin-top: 20px;
    }
  </style>
  </head>
  <body>
    <div id="loadingOverlay">
      <div>æ­£åœ¨åŠ è½½AIåŠ©æ‰‹...</div>
      <div id="loadingMessage">ğŸ¤– æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“...</div>
    </div>
    
    <h2>äº§å“å®¢æœæœºå™¨äºº</h2>
    <!-- Input section -->
    <input id="inputBox" type="text" placeholder="è¾“å…¥ä½ çš„é—®é¢˜..." disabled />
    <button onclick="sendToPyodide()" disabled>å‘é€</button>
    
    <!-- Output section -->
    <div id="outputBox"></div>

    <script type="module">
        // ä½¿ç”¨ import è¯­å¥ç›´æ¥ä» gcore å¯¼å…¥ transformers åº“
        import { pipeline } from 'https://gcore.jsdelivr.net/npm/@xenova/transformers@latest';

        // å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨åµŒå…¥ç”Ÿæˆå™¨
        window.embeddingGenerator = null;

        async function initTransformers() {
            try {
                console.log('Loading Transformers.js pipeline...');
                // åˆ›å»ºåµŒå…¥ pipeline
                window.embeddingGenerator = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
                console.log("Transformers.js pipeline created");
                return true;
            } catch (error) {
                console.error("Failed to initialize Transformers.js:", error);
                return false;
            }
        }

        // åˆå§‹åŒ– Transformers.js
        initTransformers().then(success => {
            window.transformersInitialized = success;
            if (success) {
                console.log("Transformers.js initialized successfully");
            } else {
                console.warn("Transformers.js initialization failed, will fall back to local API");
            }
        });
    </script>

    <script type="text/javascript">
      let pyodide;
      let isStreaming = false;
      let currentStream = null;

      // Function to update status from Python
      function updateStatus(message) {
        showStatus(message + " <span class='dot-flashing'></span>");
        
        // Also update the loading message if overlay is still visible
        const loadingMessage = document.getElementById('loadingMessage');
        if (loadingMessage) {
          loadingMessage.textContent = message;
        }
      }

      async function main(){
        // Show loading overlay initially
        document.getElementById('loadingOverlay').style.display = 'flex';
        
        while (!window.APP_CONFIG) {
          await new Promise(r => setTimeout(r, 50));
        }
        
        const JS_LLM_MODE = window.APP_CONFIG.LLM_MODE;
        const JS_DEEPSEEK_API_KEY = window.APP_CONFIG.DEEPSEEK_API_KEY;
        const JS_HUGGINGFACEHUB_API_TOKEN = window.APP_CONFIG.HUGGINGFACEHUB_API_TOKEN;
        const JS_TAVILY_API_KEY = window.APP_CONFIG.TAVILY_API_KEY;
        // ä»é…ç½®ä¸­è·å–åµŒå…¥æ¨¡å¼ï¼Œé»˜è®¤ä¸º "local" (ä½¿ç”¨æœ¬åœ°API)
        const JS_EMBEDDING_MODE = window.APP_CONFIG.EMBEDDING_MODE || "local";

        pyodide = await loadPyodide();
        
        // Register the updateStatus function in Python's global scope
        pyodide.globals.set("updateStatus", updateStatus);
        // å°†åµŒå…¥æ¨¡å¼ä¼ é€’ç»™ Python
        pyodide.globals.set("JS_EMBEDDING_MODE", JS_EMBEDDING_MODE);

        // --- 1. Fetch embeddings.npy ---
        updateStatus("ğŸ“¥ æ­£åœ¨åŠ è½½åµŒå…¥æ•°æ®...");
        const npyResp = await fetch("https://mofanv.github.io/dist/embeddings.npy"); // http://localhost:8001/embeddings.npy
        if (!npyResp.ok) throw new Error("åŠ è½½RAG Embeddingæ•°æ®æ–‡ä»¶å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ˜¯å¦æœ‰è®¿é—®æƒé™ã€‚");
        const npyBuffer = await npyResp.arrayBuffer();
        pyodide.FS.writeFile("/embeddings.npy", new Uint8Array(npyBuffer));

        // --- 2. Fetch embeddings_docs.json ---
        updateStatus("ğŸ“¥ æ­£åœ¨åŠ è½½æ–‡æ¡£æ•°æ®...");
        const jsonResp = await fetch("https://mofanv.github.io/dist/embeddings_docs.json"); //http://localhost:8001/embeddings_docs.json
        if (!jsonResp.ok) throw new Error("åŠ è½½RAG Docsæ•°æ®æ–‡ä»¶å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ˜¯å¦æœ‰è®¿é—®æƒé™ã€‚");
        const jsonText = await jsonResp.text();
        pyodide.FS.writeFile("/embeddings_docs.json", jsonText);

        updateStatus("ğŸ“¦ æ­£åœ¨å®‰è£…PythonåŒ…...");
        await pyodide.loadPackage("micropip");
        console.log(await pyodide.runPythonAsync(`
            import sys
            sys.version

            import micropip

            await micropip.install("requests==2.32.5", reinstall=True)
            await micropip.install([
                "numpy",
                "langchain",
                "langchain_deepseek",
                "langchain_openai",
            ], keep_going=True)

        `));
        await pyodide.runPythonAsync("print(1 + 2)");
        await pyodide.runPythonAsync(`
            import os
            os.environ['DEEPSEEK_API_KEY'] = "${JS_DEEPSEEK_API_KEY}"
            os.environ['HUGGINGFACEHUB_API_TOKEN'] = "${JS_HUGGINGFACEHUB_API_TOKEN}"
            os.environ['LLM_MODE'] = "${JS_LLM_MODE}"
            os.environ['EMBEDDING_MODE'] = "${JS_EMBEDDING_MODE}"
            print(os.environ['DEEPSEEK_API_KEY'])
            print(os.environ['HUGGINGFACEHUB_API_TOKEN'])
            print(os.environ['LLM_MODE'])
            print(os.environ['EMBEDDING_MODE'])
        `);
        
        // Now run the main Python code
        updateStatus("ğŸ æ­£åœ¨æ‰§è¡ŒPythonä»£ç ...");
        await pyodide.runPythonAsync(String.raw`
# ===================== IMPORTS =====================
import json
import os
import io
import requests
import asyncio
import time
from typing import List
import numpy as np
from langchain.schema import Document
from langchain.tools import tool
from langchain.memory import ConversationBufferMemory
from langchain.agents import initialize_agent, AgentType
from langchain_deepseek import ChatDeepSeek
from langchain_openai import ChatOpenAI

# ===================== LLM SELECTION =====================
LLM_MODE = os.getenv("LLM_MODE", "deepseek")
EMBEDDING_MODE = os.getenv("EMBEDDING_MODE", "local")
LOCAL_MODEL_NAME = os.getenv("LOCAL_MODEL_NAME", "gguf_models/Qwen3-8B-Q4_K_M.gguf")
LOCAL_API_BASE = os.getenv("LOCAL_API_BASE", "http://localhost:8000/v1")
LOCAL_API_KEY = os.getenv("LOCAL_API_KEY", "sk-no-key-required")

if LLM_MODE == "deepseek":
    llm = ChatDeepSeek(model="deepseek-chat")
    print("Calling DeepSeek as the Agent LLM...")
elif LLM_MODE == "local":
    llm = ChatOpenAI(
        model=LOCAL_MODEL_NAME,
        openai_api_base=LOCAL_API_BASE,
        openai_api_key=LOCAL_API_KEY
    )
    print("Calling Local Model as the Agent LLM...")
else:
    raise ValueError(f"Unsupported LLM_MODE: {LLM_MODE}")

print(f"Using embedding mode: {EMBEDDING_MODE}")

# ===================== KNOWLEDGE BASE (LOCAL EMBEDDINGS) =====================
EMBEDDINGS_FILE = "/embeddings.npy"
DOCS_FILE = "/embeddings_docs.json"
LOCAL_EMBEDDING_API = os.getenv("LOCAL_EMBEDDING_API", "http://localhost:8002/v1/embeddings")
LOCAL_EMBEDDING_MODEL = os.getenv("LOCAL_EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")

# Load precomputed embeddings
vectors = np.load(EMBEDDINGS_FILE, allow_pickle=True)
vectors = np.array(vectors, dtype=np.float32)  # force numeric
# Load metadata/docs corresponding to embeddings
with open(DOCS_FILE, "r", encoding="utf-8") as f:
    docs_store = [Document(page_content=d["text"], metadata=d["metadata"]) for d in json.load(f)]

# Normalize vectors safely
norms = np.linalg.norm(vectors, axis=1, keepdims=True)
vectors /= (norms + 1e-10)

def get_embedding(text: str):
    """
    Get embedding either from local API or Transformers.js based on configuration
    """
    updateStatus("ğŸ” æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...")
    
def get_embedding(text: str):
    if EMBEDDING_MODE == "transformersjs":
        import numpy as np
        if "js_embedding" in globals():
            emb = np.array(js_embedding, dtype=np.float32)
            norm = np.linalg.norm(emb)
            if norm > 0:
                emb /= norm
            return emb
        else:
            return np.zeros(vectors.shape[1], dtype=np.float32)
    else:
        # Use local API for embedding generation (original implementation)
        try:
            payload = {"model": LOCAL_EMBEDDING_MODEL, "input": [text]}
            resp = requests.post(LOCAL_EMBEDDING_API, json=payload, timeout=5)
            resp.raise_for_status()

            data = resp.json().get("data", [])
            if not data or "embedding" not in data[0]:
                # fallback to zeros
                return np.zeros(vectors.shape[1], dtype=np.float32)

            emb_list = data[0]["embedding"]
            # force all elements to float
            emb_numeric = []
            for x in emb_list:
                try:
                    emb_numeric.append(float(x))
                except Exception:
                    emb_numeric.append(0.0)

            emb = np.array(emb_numeric, dtype=np.float32)

            # normalize
            norm = np.linalg.norm(emb)
            if norm > 0:
                emb /= norm

            return emb

        except Exception as e:
            print(f"[Embedding API Error] {e}")
            return np.zeros(vectors.shape[1], dtype=np.float32)

def query_kb(query: str, k: int = 3):
    """Query the knowledge base using local embeddings"""
    updateStatus("ğŸ“š æ­£åœ¨æœç´¢çŸ¥è¯†åº“...")
    q_vec = get_embedding(query)
    
    updateStatus("ğŸ“Š æ­£åœ¨è®¡ç®—ç›¸ä¼¼åº¦...")
    sims = np.dot(q_vec, vectors.T)[0]
    top_idx = sims.argsort()[-k:][::-1]
    
    updateStatus("âœ… å·²æ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
    return [docs_store[i] for i in top_idx]

def format_with_citation(docs: List[Document]):
    return [f"{d.page_content}\næ¥æº: {d.metadata.get('url','æœªçŸ¥æ¥æº')}" for d in docs]

# ===================== TOOLS =====================
@tool
def search_knowledge(query: str):
    """æ£€ç´¢çŸ¥è¯†åº“ç›¸å…³ä¿¡æ¯ï¼Œå¹¶è¿”å›å†…å®¹ä¸æ¥æº"""
    updateStatus("ğŸ” æ­£åœ¨æœç´¢çŸ¥è¯†åº“...")
    docs = query_kb(query, k=3)
    return format_with_citation(docs)

@tool
def get_price_info(query: str):
    """æ£€ç´¢ä»·æ ¼ç›¸å…³ä¿¡æ¯"""
    updateStatus("ğŸ’° æ­£åœ¨æœç´¢ä»·æ ¼ä¿¡æ¯...")
    docs = query_kb(query, k=3)
    price_docs = [d for d in docs if "ä»·" in d.page_content or "ï¿¥" in d.page_content]
    return format_with_citation(price_docs) if price_docs else "æœªæ‰¾åˆ°ç›¸å…³ä»·æ ¼ä¿¡æ¯"

@tool
def get_spec_info(query: str):
    """æ£€ç´¢è§„æ ¼/å°ºå¯¸ç›¸å…³ä¿¡æ¯"""
    updateStatus("ğŸ“ æ­£åœ¨æœç´¢è§„æ ¼ä¿¡æ¯...")
    docs = query_kb(query, k=3)
    spec_docs = [d for d in docs if "è§„" in d.page_content or "å°ºå¯¸" in d.page_content]
    return format_with_citation(spec_docs) if spec_docs else "æœªæ‰¾åˆ°ç›¸å…³è§„æ ¼ä¿¡æ¯"

@tool
def get_comparison_info(query: str):
    """å¯¹æ¯”ä¸¤ä¸ªäº§å“æˆ–æ¡ç›®"""
    updateStatus("âš–ï¸ æ­£åœ¨æ¯”è¾ƒé¡¹ç›®...")
    parts = query.split("vs")
    if len(parts) != 2:
        return "è¯·ä½¿ç”¨ã€Œäº§å“A vs äº§å“Bã€æ ¼å¼è¿›è¡Œæ¯”è¾ƒ"
    docs1 = query_kb(parts[0].strip(), k=2)
    docs2 = query_kb(parts[1].strip(), k=2)
    return {
        "ç¬¬ä¸€æ¡ç›®": format_with_citation(docs1),
        "ç¬¬äºŒæ¡ç›®": format_with_citation(docs2)
    }

@tool
def get_summary(query: str):
    """å¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œæ‘˜è¦"""
    updateStatus("ğŸ“ æ­£åœ¨ç”Ÿæˆæ–‡æ¡£æ‘˜è¦...")
    docs = query_kb(query, k=5)
    contents = "\n".join([d.page_content for d in docs])
    return f"æ–‡æ¡£æ‘˜è¦:\n{contents}\næ¥æº: {[d.metadata.get('url','æœªçŸ¥æ¥æº') for d in docs]}"

@tool
def get_keywords(query: str):
    """æå–æ£€ç´¢æ–‡æ¡£ä¸­çš„å…³é”®è¯"""
    updateStatus("ğŸ”‘ æ­£åœ¨æå–å…³é”®è¯...")
    docs = query_kb(query, k=5)
    all_text = " ".join([d.page_content for d in docs])
    words = list(set(all_text.replace("\n"," ").split()))
    top_words = sorted(words, key=lambda w: -all_text.count(w))[:20]
    return {"keywords": top_words, "sources": [d.metadata.get('url','æœªçŸ¥æ¥æº') for d in docs]}

@tool
def get_all_sources(query: str):
    """è¿”å›æ£€ç´¢ç»“æœçš„æ‰€æœ‰æ¥æº URL"""
    updateStatus("ğŸŒ æ­£åœ¨æ”¶é›†æ¥æºä¿¡æ¯...")
    docs = query_kb(query, k=5)
    return [d.metadata.get("url","æœªçŸ¥æ¥æº") for d in docs]

# ===================== AGENT SETUP =====================
tools = [
    search_knowledge, get_price_info, get_spec_info,
    get_comparison_info, get_summary, get_keywords, get_all_sources
]

system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹ï¼ŒåŸºäºçŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœé—®é¢˜ä¸æ¸…æ¥šï¼Œè¯·ç¤¼è²Œè¯·æ±‚æ¾„æ¸…ã€‚"

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    system_message=system_prompt
)

updateStatus("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“...")
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# ===================== AGENT INTERFACE =====================
class ProductAssistantAgent:
    def __init__(self, agent_llm):
        self.agent = agent_llm

    def is_input_relevant(self, user_input: str, threshold=0.2):
        updateStatus("ğŸ” æ­£åœ¨æ£€æŸ¥æŸ¥è¯¢ç›¸å…³æ€§...")
        q_vec = get_embedding(user_input)
        vecs = vectors.astype(np.float32)  # ensure numeric

        if q_vec.shape[0] != vecs.shape[1]:
            return False

        try:
            updateStatus("ğŸ“Š æ­£åœ¨è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°...")
            sims = np.dot(q_vec, vecs.T)
            if sims.size == 0:
                return False
            max_sim = float(np.max(sims))
            return max_sim >= float(threshold)
        except (TypeError, ValueError):
            return False

    async def process_message(self, message: str):
        if not self.is_input_relevant(message):
            return "æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç†è§£æ‚¨çš„é—®é¢˜ã€‚å¯ä»¥è¯·æ‚¨æè¿°å¾—æ›´æ¸…æ¥šå—ï¼Ÿ"

        # Run agent
        updateStatus("ğŸ§  æ­£åœ¨æ€è€ƒå¦‚ä½•å›ç­”...")
        ai_raw = self.agent.invoke(message)

        # Only keep the AI response content
        if hasattr(ai_raw, "content"):
            ai_response = ai_raw.content
        elif isinstance(ai_raw, dict) and "output" in ai_raw:
            ai_response = ai_raw["output"]
        else:
            ai_response = str(ai_raw)

        return ai_response

# ===================== GLOBAL AGENT INSTANCE =====================
agent_instance = ProductAssistantAgent(agent_llm=agent)

# ===================== MAIN FUNCTION =====================
async def main_function(user_input: str) -> str:
    updateStatus("ğŸ¤– æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...")
    res = await agent_instance.process_message(user_input)
    return res

        `);
        
        // Hide the loading overlay and enable input
        document.getElementById('loadingOverlay').style.display = 'none';
        document.getElementById('inputBox').disabled = false;
        document.querySelector('button').disabled = false;
        document.getElementById('inputBox').focus();
        
        // Clear any status messages in the chat output
        hideStatus();
      }
      
      // Start initialization when page loads
      main().catch(error => {
        console.error("Initialization error:", error);
        document.getElementById('loadingMessage').textContent = "âŒ åˆå§‹åŒ–å¤±è´¥: " + error.message;
      });

      // === Chat UI functions ===
      async function sendToPyodide() {
        if (isStreaming) {
          // If already streaming, cancel the current stream
          if (currentStream) {
            clearInterval(currentStream);
            currentStream = null;
          }
          // Remove the cursor
          const cursor = document.querySelector('.typing-cursor');
          if (cursor) cursor.remove();
          isStreaming = false;
        }
        
        const userInput = document.getElementById("inputBox").value;
        if (!userInput.trim()) return;
        
        logOutput("ğŸ‘¤ ç”¨æˆ·: " + userInput, "user");

        // Disable input during processing
        document.getElementById("inputBox").value = "";
        document.getElementById("inputBox").disabled = true;
        document.querySelector('button').disabled = true;

        // Show initial status
        showStatus("ğŸ¤– æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚ <span class='dot-flashing'></span>");

        try {
          // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ Transformers.js æ¨¡å¼
          const embeddingMode = window.APP_CONFIG.EMBEDDING_MODE || "local";
          
          if (embeddingMode === "transformersjs" && window.embeddingGenerator) {
            // ä½¿ç”¨ Transformers.js ç”ŸæˆåµŒå…¥
            showStatus("ğŸ§  æ­£åœ¨ä½¿ç”¨ Transformers.js ç”ŸæˆåµŒå…¥ <span class='dot-flashing'></span>");
            
            // ç”ŸæˆåµŒå…¥å‘é‡
            const output = await window.embeddingGenerator(userInput, { pooling: 'mean', normalize: true });
            const embeddingArray = Array.from(output.data);
            
            // å°†åµŒå…¥å‘é‡ä¼ é€’ç»™ Pyodide
            pyodide.globals.set("js_embedding", embeddingArray);
            
            // è°ƒç”¨ Python å‡½æ•°å¤„ç†åµŒå…¥å‘é‡
            await pyodide.runPythonAsync(`
                import numpy as np
                # ä½¿ç”¨ JavaScript ä¼ é€’çš„åµŒå…¥å‘é‡
                js_embedding = np.array(js_embedding, dtype=np.float32)
                # å½’ä¸€åŒ–
                norm = np.linalg.norm(js_embedding)
                if norm > 0:
                    js_embedding /= norm
                # æ›¿æ¢å…¨å±€å‘é‡ç”¨äºåç»­å¤„ç†
                vectors_global = vectors
                # è®¡ç®—ç›¸ä¼¼åº¦
                sims = np.dot(js_embedding, vectors_global.T)[0]
                top_idx = sims.argsort()[-3:][::-1]
                # è·å–ç›¸å…³æ–‡æ¡£
                relevant_docs = [docs_store[i] for i in top_idx]
                # å°†ç»“æœå­˜å‚¨ä¸ºå…¨å±€å˜é‡ä¾›åç»­ä½¿ç”¨
                relevant_docs_global = relevant_docs
            `);
            
            // ç»§ç»­å¤„ç†ç”¨æˆ·è¾“å…¥
            const result = await pyodide.runPythonAsync(`
                await main_function(${JSON.stringify(userInput)})
            `);
            
            // Clear status
            hideStatus();
            
            // Start streaming the response
            streamOutput("ğŸ¤– åŠ©æ‰‹: " + result, "assistant");
          } else {
            // ä½¿ç”¨é»˜è®¤çš„æœ¬åœ° API æ¨¡å¼
            const result = await pyodide.runPythonAsync(`
                await main_function(${JSON.stringify(userInput)})
            `);
            
            // Clear status
            hideStatus();
            
            // Start streaming the response
            streamOutput("ğŸ¤– åŠ©æ‰‹: " + result, "assistant");
          }
        } catch (err) {
          // Clear status
          hideStatus();
          
          logOutput("âš ï¸ é”™è¯¯: " + err, "error");
          // Re-enable input on error
          document.getElementById("inputBox").disabled = false;
          document.querySelector('button').disabled = false;
        }
      }

      document.getElementById("inputBox").addEventListener("keydown", function(event) {
          if (event.key === "Enter") {
              event.preventDefault(); // prevent newline in input
              sendToPyodide();
          }
      });

      function logOutput(message, type="assistant") {
          const out = document.getElementById("outputBox");

          // Create a span element for message
          const span = document.createElement("span");
          span.textContent = message;

          if (type === "user") {
              span.style.color = "#1E90FF"; // blue for ç”¨æˆ·
              span.style.fontWeight = "bold";
          } else if (type === "assistant") {
              span.style.color = "#32CD32"; // green for åŠ©æ‰‹
          } else if (type === "error") {
              span.style.color = "#FF4500"; // red for errors
              span.style.fontWeight = "bold";
          }

          out.appendChild(span);
          out.appendChild(document.createElement("br")); // line break
          out.appendChild(document.createElement("br")); // extra spacing

          out.scrollTop = out.scrollHeight; // auto-scroll
      }
      
      function streamOutput(message, type) {
          isStreaming = true;
          const out = document.getElementById("outputBox");
          
          // Create a span for the message
          const span = document.createElement("span");
          if (type === "assistant") {
              span.style.color = "#32CD32"; // green for åŠ©æ‰‹
          }
          
          out.appendChild(span);
          
          // Create a blinking cursor
          const cursor = document.createElement("span");
          cursor.className = "typing-cursor";
          out.appendChild(cursor);
          
          let i = 0;
          currentStream = setInterval(() => {
              if (i < message.length) {
                  span.textContent += message[i];
                  i++;
                  out.scrollTop = out.scrollHeight; // auto-scroll
              } else {
                  // Finished streaming
                  clearInterval(currentStream);
                  currentStream = null;
                  isStreaming = false;
                  
                  // Remove the cursor
                  cursor.remove();
                  
                  // Add line breaks
                  out.appendChild(document.createElement("br"));
                  out.appendChild(document.createElement("br"));
                  
                  // Re-enable input
                  document.getElementById("inputBox").disabled = false;
                  document.querySelector('button').disabled = false;
                  document.getElementById("inputBox").focus();
              }
          }, 30); // Adjust speed as needed (milliseconds per character)
      }
      
      function showStatus(message) {
          // Remove any existing status
          hideStatus();
          
          const out = document.getElementById("outputBox");
          const statusElement = document.createElement("div");
          statusElement.id = "status-indicator";
          statusElement.className = "status-indicator";
          statusElement.innerHTML = message;
          
          out.appendChild(statusElement);
          out.scrollTop = out.scrollHeight;
      }
      
      function hideStatus() {
          const statusElement = document.getElementById("status-indicator");
          if (statusElement) {
              statusElement.remove();
          }
      }

    </script>
  </body>
</html>